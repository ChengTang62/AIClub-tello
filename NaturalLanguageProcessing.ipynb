{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ba66aa4-7642-4e68-a7e7-06d1b0387161",
   "metadata": {},
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acf71e2-a7bd-4442-8687-fcddd7a57d7b",
   "metadata": {},
   "source": [
    "Natural Language Processing (NLP): NLP is a branch of AI that focuses on enabling computers to understand, interpret, and manipulate human language. This technology is at the core of various applications like language translation services, chatbots, and sentiment analysis tools. NLP combines computational linguistics—rule-based modeling of human language—with statistical, machine learning, and deep learning models. These models enable computers to process human language in the form of text or voice data and 'understand' its full meaning, complete with the speaker's or writer's intentions and sentiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45aa06a-422f-4758-a304-d5a288ced72d",
   "metadata": {},
   "source": [
    "## Voice Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e776d9ae-6fcb-479c-b70b-ead509104bf4",
   "metadata": {},
   "source": [
    "<img src=\"voice_recognition.jpeg\" style=\"float: left;\" width=\"300\" height=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd75b172-2588-4a89-85ea-c47e9b7a3d40",
   "metadata": {},
   "source": [
    "Voice Recognition: This technology, also known as speech recognition, enables a computer to process and transcribe spoken language. It's a critical component of many voice-controlled applications and devices, allowing for hands-free control and dictation. Voice recognition technology is used in virtual assistant devices like Amazon's Alexa, Apple's Siri, and Google Assistant, as well as in applications that require transcription of spoken words into written text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ee1dacd-0220-4dc7-a603-01a19aa7013c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "# Initialize recognizer\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Record audio (from microphone or audio file)\n",
    "with sr.Microphone() as source:\n",
    "    print(\"Speak Now...\")\n",
    "    audio_data = recognizer.listen(source)\n",
    "    print(\"Recognizing...\")\n",
    "\n",
    "    # Convert speech to text\n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio_data)\n",
    "        print(f\"You said: {text}\")\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Sorry, I did not understand that.\")\n",
    "    except sr.RequestError:\n",
    "        print(\"Sorry, my speech service is down.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b5cd3e-7ce7-45c4-8d8a-202545a93cbd",
   "metadata": {},
   "source": [
    "These code snippets demonstrate basic implementations. The NLP example uses the Natural Language Toolkit (NLTK), a leading platform for building Python programs to work with human language data. It performs sentiment analysis on a given text. The voice recognition example uses the SpeechRecognition library, which makes it easy to recognize speech and convert it to text. Remember, these libraries require installation and proper setup in your Python environment. Additionally, the voice recognition example assumes the presence of a microphone or an audio source for capturing speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2c9632a-d680-41e3-a95c-52a6b0d7dbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "from djitellopy import Tello\n",
    "\n",
    "# Initialize the recognizer and drone\n",
    "recognizer = sr.Recognizer()\n",
    "drone = Tello()\n",
    "\n",
    "# Connect to the drone\n",
    "drone.connect()\n",
    "print(f\"Drone Battery: {drone.get_battery()}%\")\n",
    "\n",
    "# Function to process voice commands\n",
    "def process_command(command):\n",
    "    if 'take off' in command:\n",
    "        drone.takeoff()\n",
    "        print(\"Drone Taking Off\")\n",
    "    elif 'land' in command:\n",
    "        drone.land()\n",
    "        print(\"Drone Landing\")\n",
    "    elif 'left' in command:\n",
    "        drone.move_left(30)\n",
    "        print(\"Moving Left\")\n",
    "    elif 'right' in command:\n",
    "        drone.move_right(30)\n",
    "        print(\"Moving Right\")\n",
    "    elif 'forward' in command:\n",
    "        drone.move_forward(30)\n",
    "        print(\"Moving Forward\")\n",
    "    elif 'back' in command:\n",
    "        drone.move_back(30)\n",
    "        print(\"Moving Back\")\n",
    "    elif 'up' in command:\n",
    "        drone.move_up(30)\n",
    "        print(\"Moving Up\")\n",
    "    elif 'down' in command:\n",
    "        drone.move_down(30)\n",
    "        print(\"Moving Down\")\n",
    "    else:\n",
    "        print(\"Command not recognized\")\n",
    "\n",
    "# Listen and execute commands\n",
    "with sr.Microphone() as source:\n",
    "    try:\n",
    "        while True:\n",
    "            print(\"Listening for commands...\")\n",
    "            audio = recognizer.listen(source)\n",
    "            command = recognizer.recognize_google(audio).lower()\n",
    "            process_command(command)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Voice command control terminated.\")\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Sorry, I did not understand that.\")\n",
    "    except sr.RequestError:\n",
    "        print(\"Sorry, my speech service is down.\")\n",
    "    finally:\n",
    "        drone.land()\n",
    "        drone.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339f62ab-7dbd-4950-af12-8da9dd8706ae",
   "metadata": {},
   "source": [
    "**<font face=\"Verdana\" style=\"font-size: large\" color=\"red\">Try it Yourself</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2439be42-d3dd-4ec0-b471-0211994fe8da",
   "metadata": {},
   "source": [
    "<img src=\"drone_flight_path.png\" style=\"float: left;\" width=\"300\" height=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e040a1d6-1c21-4207-84a7-1f0ddaf1b297",
   "metadata": {},
   "source": [
    "**<font face=\"Verdana\" style=\"font-size: large\" color=\"blue\">Command the robot to move to a specific spot</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196d8e8a-0f70-4a50-a141-7b55c31a1e1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
